# üî• Awesome Robust Driving World Models 

This repository focuses on **driving world models (DWM)** with an emphasis on their **task taxonomy** and **progressive robustness (Robustness 1.0 ‚Üí 3.0)**, base on the survey:

[[**Progressive Robustness-Aware World Models in Autonomous Driving: A Review and Outlook**](https://doi.org/10.36227/techrxiv.176523308.84756413/v1)]

## Citation

If you find this repository or the survey useful, please consider ‚≠ê this repo and citing the paper.

```bibtex
@article{jia2025progressive,
  title   = {{Progressive Robustness-Aware World Models in Autonomous Driving: A Review and Outlook}},
  author  = {Feiyang Jia and Caiyan Jia and Ziying Song and Zhicheng Bao and Lin Liu and Shaoqing Xu and Yan Gong and Lei Yang and Xinyu Zhang and Bin Sun and Xiaoshuai Hao and Long Chen and Yadan Luo},
  journal = {TechRxiv},
  year    = {2025},
  note    = {preprint},
  doi     = {10.36227/techrxiv.176523308.84756413/v1}
}
```

## Paper Recommendations 

If you‚Äôd like to suggest something, please open an new ISSUE page and (if possible) provide:

1. **Online link** to the paper / project homepage / code repository. 
2. The suggested **category**, following this repo:
   - Task: Generation / Planning / Enhancement
   - Robustness level: Robustness 1.0 / 2.0 / 3.0

---

# üìå Overview of Contents

- üìÑ 1. Summary: Information, Task, and Robustness Level
- üõ°Ô∏è 2. Progressive Robustness Analysis: 1.0, 2.0 and 3.0
  - 2.1 Robustness 1.0 ‚Äì Self-Metrics & Evaluation Protocols
  - 2.2 Robustness 2.0 ‚Äì Contributions to Autonomous Driving Systems
  - 2.3 Robustness 3.0 ‚Äì Open-World Robustness & Future Directions

---

# üìÑ 1. Summary: Information, Task, and Robustness Level
**2022**
| Abbr.      | Pub.     | Full Title | Paper  | Page | Code | Gene. | Plan. | Enh. | Lv. |
|:-----------------:|:---------:|:-----------|:------:|:----:|:----:|:----------:|:--------:|:-----------:|:-----------------:|
| **Iso-Dream** | NIPS2022 | Iso-dream: Isolating and leveraging noncontrollable visual dynamics in world models | [[‚úì](https://proceedings.neurips.cc/paper_files/paper/2022/hash/9316769afaaeeaad42a9e3633b14e801-Abstract-Conference.html)] | ‚úó | [[‚úì](https://github.com/panmt/Iso-Dream)] | ‚úì | ‚úì | ‚úó | 2.0 |
| **SEM2** | NIPS2022 | Model-based imitation learning for urban driving | [[‚úì](https://arxiv.org/abs/2210.04017)] | ‚úó | ‚úó | ‚úì | ‚úì | ‚úó | 2.0 |
| **MILE** | NIPS2022 | SEM2: Enhance Sample Efficiency and Robustness of End-to-end Urban Autonomous Driving via Semantic Masked World Model | [[‚úì](https://proceedings.neurips.cc/paper_files/paper/2022/hash/827cb489449ea216e4a257c47e407d18-Abstract-Conference.html)] | ‚úó | [[‚úì](https://github.com/wayveai/mile)] | ‚úì | ‚úì | ‚úó | 2.0 |

**2023**
| Abbr.      | Pub.     | Full Title | Paper  | Page | Code | Gene. | Plan. | Enh. | Lv. |
|:-----------------:|:---------:|:-----------|:------:|:----:|:----:|:----------:|:--------:|:-----------:|:-----------------:|
| **ADriver-I** | arXiv2311 | ADriver-I: A General World Model for Autonomous Driving | [[‚úì](https://arxiv.org/abs/2311.13549)] | ‚úó | ‚úó | ‚úì | ‚úì | ‚úó | 2.0 |
| **GAIA-1** | arXiv2309 | GAIA-1: A Generative World Model for Autonomous Driving | [[‚úì](https://arxiv.org/abs/2309.17080)] | ‚úó | ‚úó | ‚úì | ‚úó | ‚úó | 2.0 |
| **UniWorld** | arXiv2308 | UniWorld: Autonomous Driving Pre-training via World Models | [[‚úì](https://arxiv.org/abs/2308.07234)] | ‚úó | [[‚úì](https://github.com/chaytonmin/UniWorld)] | ‚úì | ‚úó | ‚úì | 2.0 |
| **TrafficBots** | ICRA23 | TrafficBots: Towards World Models for Autonomous Driving Simulation and Motion Prediction | [[‚úì](https://arxiv.org/abs/2303.04116)] | ‚úó | [[‚úì](https://github.com/SysCV/TrafficBots)] | ‚úì | ‚úì | ‚úó | 2.0 |

**2024**
| Abbr.      | Pub.     | Full Title | Paper  | Page | Code | Gene. | Plan. | Enh. | Lv. |
|:-----------------:|:---------:|:-----------|:------:|:----:|:----:|:----------:|:--------:|:-----------:|:-----------------:|
|   **DrivingWorld**   | arXiv 2024.12 | DrivingWorld: Constructing World Model for Autonomous Driving via Video GPT                                         | [[‚úì](https://arxiv.org/abs/2412.19505)] |                                      ‚úó                                      |                          [[‚úì](https://github.com/YvanYin/DrivingWorld)]                          |  ‚úì  |  ‚úó  |  ‚úó  | 2.0 |
|  **InfinityDrive**  | arXiv 2024.12 | InfinityDrive: Breaking Time Limits in Driving World Models                                                         | [[‚úì](https://arxiv.org/abs/2412.01522)] | [[‚úì](https://metadrivescape.github.io/papers_project/InfinityDrive/page.html)] |                                               ‚úó                                               |  ‚úì  |  ‚úó  |  ‚úó  | 2.0 |
|      **GenAD**      |   CVPR 2024   | Generalized Predictive Model for Autonomous Driving                                                                 | [[‚úì](https://arxiv.org/abs/2403.09630)] |                                      ‚úó                                      | [[Data](https://github.com/OpenDriveLab/DriveAGI?tab=readme-ov-file#genad-dataset-opendv-youtube)] |  ‚úì  |  ‚úì  |  ‚úó  | 2.0 |
|      **TERRA**      | arXiv 2024.12 | Towards Action Controllable World Models for Autonomous Driving                                                     | [[‚úì](https://arxiv.org/abs/2412.05337)] |                [[‚úì](https://turingmotors.github.io/actbench/)]                |                         [[‚úì](https://github.com/turingmotors/ACT-Bench)]                         |  ‚úì  |  ‚úì  |  ‚úó  | 2.0 |
|      **Vista**      | NeurIPS 2024 | Vista: A Generalizable Driving World Model with High Fidelity and Versatile Controllability                         | [[‚úì](https://arxiv.org/abs/2405.17398)] |                                      ‚úó                                      |                           [[‚úì](https://github.com/OpenDriveLab/Vista)]                           |  ‚úì  |  ‚úì  |  ‚úó  | 2.0 |
|  **DINO-Foresight**  | arXiv 2024.12 | DINO-Foresight: Self-Supervised Semantic Foresight for Autonomous Driving                                           | [[‚úì](https://arxiv.org/abs/2412.11673)] |                                      ‚úó                                      |                          [[‚úì](https://github.com/Sta8is/DINO-Foresight)]                          |  ‚úì  |  ‚úó  |  ‚úó  | 2.0 |
|   **DriveGenVLM**   |  IAVVC 2024  | DriveGenVLM: Real-world Video Generation for Autonomous Driving with Vision Language Models                         | [[‚úì](https://arxiv.org/abs/2408.16647)] |                                      ‚úó                                      |                                               ‚úó                                               |  ‚úì  |  ‚úó  |  ‚úó  | 2.0 |
|      **Doe-1**      | arXiv 2024.12 | Doe-1: Driving on Earth with One Transformer                                                                        | [[‚úì](https://arxiv.org/abs/2412.09627)] |                                      ‚úó                                      |                               [[‚úì](https://github.com/wzzheng/Doe)]                               |  ‚úì  |  ‚úì  |  ‚úó  | 2.0 |
|     **UniMLVG**     | arXiv 2024.12 | UniMLVG: Unified Multi-View LiDAR-Video Generation for Autonomous Driving                                           | [[‚úì](https://arxiv.org/abs/2412.09628)] |                [[‚úì](https://sensetime-fvg.github.io/UniMLVG/)]                |                          [[‚úì](https://github.com/SenseTime-FVG/OpenDWM)]                          |  ‚úì  |  ‚úó  |  ‚úó  | 2.0 |
|     **Drive-WM**     |   CVPR 2024   | Driving into the Future: Multiview Visual Forecasting and Planning with World Model for Autonomous Driving          | [[‚úì](https://arxiv.org/abs/2311.17918)] |                       [[‚úì](https://drive-wm.github.io/)]                       |                           [[‚úì](https://github.com/BraveGroup/Drive-WM)]                           |  ‚úì  |  ‚úì  |  ‚úó  | 2.0 |
|   **DriveDreamer**   |   ECCV 2024   | DriveDreamer: Towards Real-world-driven Generative World Models for Autonomous Driving                              | [[‚úì](https://arxiv.org/abs/2309.09777)] |                     [[‚úì](https://drivedreamer.github.io/)]                     |                        [[‚úì](https://github.com/JeffWang987/DriveDreamer)]                        |  ‚úì  |  ‚úì  |  ‚úì  | 2.0 |
| **DrivingDiffusion** |   ECCV 2024   | Layout-Guided multi-view driving scene video generation with latent diffusion model                                 | [[‚úì](https://arxiv.org/abs/2310.07771)] |                   [[‚úì](https://drivingdiffusion.github.io/)]                   |                        [[‚úì](https://github.com/shalfun/DrivingDiffusion)]                        |  ‚úì  |  ‚úó  |  ‚úì  | 2.0 |
|   **DrivePhysica**   | arXiv 2024.12 | DrivePhysica: Physical-Consistent Video Generation for Autonomous Driving                                           | [[‚úì](https://arxiv.org/abs/2412.09621)] |                                      ‚úó                                      |           [[‚úì](https://metadrivescape.github.io/papers_project/DrivePhysica/page.html)]           |  ‚úì  |  ‚úó  |  ‚úì  | 2.0 |
|     **Panacea**     |   CVPR 2024   | Panoramic and Controllable Video Generation for Autonomous Driving                                                  | [[‚úì](https://arxiv.org/abs/2311.16813)] |                      [[‚úì](https://panacea-ad.github.io/)]                      |                            [[‚úì](https://github.com/wenyuqing/panacea)]                            |  ‚úì  |  ‚úó  |  ‚úì  | 2.0 |
|    **DriveScape**    | arXiv 2024.09 | DriveScape: Towards High-Resolution Controllable Multi-View Driving Video Generation                                | [[‚úì](https://arxiv.org/abs/2409.05463)] |                                      ‚úó                                      |                                               ‚úó                                               |  ‚úì  |  ‚úó  |  ‚úì  | 2.0 |
|    **HoloDrive**    | arXiv 2024.12 | Holistic 2D-3D Multi-Modal Street Scene Generation for Autonomous Driving                                                      | [[‚úì](https://arxiv.org/abs/2412.01407)] |                                      ‚úó                                      |                                               ‚úó                                               |  ‚úì  |  ‚úó  |  ‚úó  | 2.0 |
|     **WoVoGen**     |   ECCV 2024   | World Volume-aware Diffusion for Controllable Multi-camera Driving Scene Generation                                                   | [[‚úì](https://arxiv.org/abs/2312.02934)] |                      ‚úó                       |             [[‚úì](https://github.com/fudan-zvg/WoVoGen)]                                                                                  |  ‚úì  |  ‚úó  |  ‚úó  | 2.0 |
|    **Copilot4D**    |   ICLR 2024   | Learning Unsupervised World Models for Autonomous Driving via Discrete Diffusion                                                  | [[‚úì](https://arxiv.org/abs/2311.01017)] |                                      ‚úó                                      |                     ‚úó                          |  ‚úì  |  ‚úó  |  ‚úó  | 2.0 |
|  **DFIT-OccWorld**  | arXiv 2024.12 | An Efficient Occupancy World Model via Decoupled Dynamic Flow and Image-assisted Training                                                             | [[‚úì](https://arxiv.org/abs/2412.13772)] |                                      ‚úó                                      |                                               ‚úó                                               |  ‚úì  |  ‚úì  |  ‚úó  | 2.0 |
|      **ViDAR**      |   CVPR 2024   | Visual Point Cloud Forecasting enables Scalable Autonomous Driving                                                                  | [[‚úì](https://arxiv.org/abs/2312.17655)] |                                      ‚úó                                      |                           [[‚úì](https://github.com/OpenDriveLab/ViDAR)]                           |  ‚úì  |  ‚úì  |  ‚úì  | 2.0 |
|       **UnO**       |   CVPR 2024   | Unsupervised Occupancy Fields for Perception and Forecasting                                                  | [[‚úì](https://arxiv.org/abs/2406.08691)] |                                       [[‚úì](https://waabi.ai/research/uno)]                                      |                             [[‚úì](https://waabi.ai/research/uno)]                              |  ‚úì  |  ‚úó  |  ‚úì  | 2.0 |
|     **OccWorld**     |   ECCV 2024   | OccWorld: Learning a 3D Occupancy World Model for Autonomous Driving                                                | [[‚úì](https://arxiv.org/abs/2311.16038)] |                      [[‚úì](https://wzzheng.net/OccWorld)]                      |                            [[‚úì](https://github.com/wzzheng/OccWorld)]                            |  ‚úì  |  ‚úì  |  ‚úó  | 2.0 |
|       **DOME**       | arXiv 2024.10 | Taming Diffusion Model into High-Fidelity Controllable Occupancy World Model                                              | [[‚úì](https://arxiv.org/abs/2410.10429)] |                     [[‚úì](https://gusongen.github.io/DOME)]                     |                 [[‚úì](https://github.com/gusongen/DOME)]                                                                                |  ‚úì  |  ‚úó  |  ‚úó  | 2.0 |
|    **DriveWorld**    |   CVPR 2024   | 4D Pre-trained Scene Understanding via World Models for Autonomous Driving                                                                  | [[‚úì](https://arxiv.org/abs/2405.04390)] |                                      ‚úó                                      |                       ‚úó                            |  ‚úì  |  ‚úì  |  ‚úì  | 2.0 |
|     **Cam4DOCC**     |   CVPR 2024   | Cam4DOcc: Benchmark for Camera-Only 4D Occupancy Forecasting in Autonomous Driving Applications                     | [[‚úì](https://arxiv.org/abs/2311.17663)] |                            ‚úó            |                            [[‚úì](https://github.com/haomo-ai/Cam4DOcc)]                            |  ‚úì  |  ‚úó  |  ‚úó  | 2.0 |
|     **OccSora**     | arXiv 2024.05 | OccSora: 4D Occupancy Generation Models as World Simulators for Autonomous Driving                                  | [[‚úì](https://arxiv.org/abs/2405.17833)] |                                      ‚úó                                      |                             [[‚úì](https://github.com/haomo-ai/Cam4DOcc)]                             |  ‚úì  |  ‚úó  |  ‚úó  | 2.0 |
|       **NeMo**       |   ECCV 2024   | Neural Volumetric World Models for Autonomous Driving                                                                                 | [[‚úì](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/02571.pdf)] |                                      ‚úó                                      |                            ‚úó                            |  ‚úì  |  ‚úì  |  ‚úì  | 2.0 |
|     **OccLLaMA**     | arXiv 2024.09 | An Occupancy-Language-Action Generative World Model for Autonomous Driving                                                       | [[‚úì](https://arxiv.org/abs/2409.03272)] |                                      ‚úó                                      |                            ‚úó                            |  ‚úì  |  ‚úì  |  ‚úó  | 2.0 |
|       **LAW**       | arXiv 2024.06 | Enhancing End-to-end Autonomous Driving with Latent World Model                                                     | [[‚úì](https://arxiv.org/abs/2406.08481)] |                                      ‚úó                                      |                             [[‚úì](https://github.com/BraveGroup/LAW)]                             |  ‚úì  |  ‚úì  |  ‚úó  | 2.0 |
|    **CarFormer**    |   ECCV 2024   | CarFormer: Self-Driving with Learned Object-Centric Representations                                                 | [[‚úì](https://arxiv.org/abs/2407.15843)] |                  [[‚úì](https://kuis-ai.github.io/CarFormer/)]                  |                            [[‚úì](https://github.com/Shamdan17/CarFormer)]                            |  ‚úì  |  ‚úì  |  ‚úó  | 2.0 |
|      **GenAD**      |   ECCV 2024   | Generative End-to-End Autonomous Driving                                                                     | [[‚úì](https://arxiv.org/abs/2402.11502)] |                     ‚úó                      |                              [[‚úì](https://github.com/wzzheng/GenAD)]                              |  ‚úì  |  ‚úì  |  ‚úì  | 2.0 |
|  **SceneDiffuser**  | NeurIPS 2024 | Efficient and Controllable Driving Simulation Initialization and Rollout                                                   | [[‚úì](https://arxiv.org/abs/2412.12129)] |                                      ‚úó                                      |                         ‚úó                     |  ‚úì  |  ‚úì  |  ‚úó  | 2.0 |
|     **MARL-CCE**     |   ECCV 2024   | Modelling Competitive Behaviors in Autonomous Driving Under Generative World Model      | [[‚úì](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/05085.pdf)] |                                      ‚úó                                      |                          [[‚úì](https://github.com/qiaoguanren/MARL-CCE)]                          |  ‚úì  |  ‚úó  |  ‚úó  | 2.0 |
|      **RAMBLE**      | arXiv 2024.10 | From Imitation to Exploration: End-to-end Autonomous Driving based on World Model                                                               | [[‚úì](https://arxiv.org/abs/2410.02253)] |           ‚úó           |                              ‚úó                              |  ‚úì  |  ‚úì  |  ‚úó  | 2.0 |
| **Imagine-2-Drive** | arXiv 2024.11 | High-Fidelity World Modeling in CARLA for Autonomous Vehicles                                                       | [[‚úì](https://arxiv.org/abs/2411.10171)] |                                   [[‚úì](https://anantagrg.github.io/Imagine-2-Drive.github.io/)]                                         |                                               ‚úó                                               |  ‚úì  |  ‚úó  |  ‚úó  | 2.0 |
|   **Popov et al.**   | arXiv 2024.09 | Mitigating Covariate Shift in Imitation Learning for Autonomous Vehicles Using Latent Space Generative World Models | [[‚úì](https://arxiv.org/abs/2409.16663)] |                                      ‚úó                                      |                                               ‚úó                                               |  ‚úì  |  ‚úì  |  ‚úó  | 2.0 |
|   **Think2Drive**   |   ECCV 2024   | Efficient Reinforcement Learning by Thinking in Latent World Model for Quasi-Realistic Autonomous Driving      | [[‚úì](https://arxiv.org/abs/2402.16720)] |                 ‚úó                 |                          ‚úó                        |  ‚úì  |  ‚úì  |  ‚úó  | 2.0 |
|       **GUMP**       |   ECCV 2024   | Solving Motion Planning Tasks with a Scalable Generative Model                                                                    | [[‚úì](https://arxiv.org/abs/2407.02797)] |                  ‚úó                  |                               [[‚úì](https://github.com/HorizonRobotics/GUMP/)]                               |  ‚úì  |  ‚úì  |  ‚úó  | 2.0 |

**2025**
| Abbr.      | Pub.     | Full Title | Paper  | Page | Code | Gene. | Plan. | Enh. | Lv. |
|:-----------------:|:---------:|:-----------|:------:|:----:|:----:|:----------:|:--------:|:-----------:|:-----------------:|
|        **Dreamland** |  arXiv2506  | Dreamland: Controllable World Creation with Simulator and Generative Models                                                            |                                                                            [[‚úì](https://arxiv.org/abs/2506.08006)]                                                                            | [[‚úì](https://metadriverse.github.io/dreamland/)] |                                 ‚úó                                  |   ‚úì   |   ‚úó   |  ‚úó   | 2.0 |
|          **Orbis** |  arXiv2507  | Orbis: Overcoming Challenges of Long-Horizon Prediction in Driving World Models                                                        |                                                                            [[‚úì](https://arxiv.org/abs/2507.13162)]                                                                            |                     ‚úó                      |            [[‚úì](https://github.com/lmb-freiburg/Orbis)]            |   ‚úì   |   ‚úó   |  ‚úó   | 2.0 |
|      **ReconDreamer** |  CVPR 2025  | ReconDreamer: Crafting World Models for Driving Scene Reconstruction via Online Restoration                                            |                                                                            [[‚úì](https://arxiv.org/abs/2411.19548)]                                                                            |                     ‚úó                      |       [[‚úì](https://github.com/GigaAI-research/ReconDreamer)]       |   ‚úì   |   ‚úó   |  ‚úó   | 2.0 |
|       **ProphetDWM** |  arXiv2505  | ProphetDWM: A Driving World Model for Rolling Out Future Actions and Videos                                                            |                                                                            [[‚úì](https://arxiv.org/abs/2505.18650)]                                                                            |                     ‚úó                      |                                 ‚úó                                  |   ‚úì   |   ‚úó   |  ‚úó   | 2.0 |
|         **FSDrive** | NeurIPS 2025 | FutureSightDrive: Thinking Visually with Spatio-Temporal CoT for Autonomous Driving                                                    |                                                                            [[‚úì](https://arxiv.org/abs/2505.17685)]                                                                            |                     ‚úó                      |             [[‚úì](https://github.com/MIV-XJTU/FSDrive)]             |   ‚úì   |   ‚úì   |  ‚úó   | 2.0 |
|       **DrivingGPT** |  ICCV 2025  | DrivingGPT: Unifying Driving World Modeling and Planning with Multi-modal Autoregressive Transformers                                  |                                                                         [[‚úì](https://rogerchern.github.io/DrivingGPT/)]                                                                         | [[‚úì](https://rogerchern.github.io/DrivingGPT/)] |                                 ‚úó                                  |   ‚úì   |   ‚úì   |  ‚úó   | 2.0 |
|          **Epona** |  ICCV 2025  | Epona: Autoregressive Diffusion World Model for Autonomous Driving                                                                     |                                                                            [[‚úì](https://arxiv.org/abs/2506.24113)]                                                                            |    [[‚úì](https://kevin-thu.github.io/Epona/)]     |               [[‚úì](https://github.com/Kevin-thu/Epona)]                |   ‚úì   |   ‚úì   |  ‚úó   | 2.0 |
|       **ImagiDrive** |  arXiv2508  | ImagiDrive: A Unified Imagination-and-Planning Framework for Autonomous Driving                                                        |                                                                            [[‚úì](https://arxiv.org/abs/2508.11428)]                                                                            |                     ‚úó                      |            [[‚úì](https://github.com/fudan-zvg/ImagiDrive)]            |   ‚úì   |   ‚úì   |  ‚úó   | 2.0 |

|    **GeoDrive** | arXiv2505  | GeoDrive: Geometry-Aware Driving World Model                                                 |            [[‚úì](https://arxiv.org/abs/2406.09756)]            |                       ‚úó                       |           [[‚úì](https://github.com/Find-C/GeoDrive)]          |   ‚úì   |   ‚úì   |  ‚úó   | 2.0 |
|     **ReSim** | arXiv2506  | ReSim: Reliable World Simulation for Autonomous Driving                                      |            [[‚úì](https://arxiv.org/abs/2506.09981)]            |                       ‚úó                       |      [[‚úì](https://github.com/Tsinghua-MARS-Lab/ReSim)]       |   ‚úì   |   ‚úì   |  ‚úó   | 2.0 |
|     **VaViM** | arXiv2502  | VaViM and VaVAM: Autonomous Driving through Video Generative Modeling                        |   [[‚úì](https://arxiv.org/abs/2502.00000)]<br>*(Preprint)* | [[‚úì](https://valeoai.github.io/vavim-vavam/)] |    [[‚úì](https://github.com/valeoai/VideoActionModel)]    |   ‚úì   |   ‚úì   |  ‚úì   | 2.0 |
| **DriveDreamer4D** | CVPR 2025  | DriveDreamer4D: World Models Are Effective Data Machines for 4D Driving Scene Representation |            [[‚úì](https://arxiv.org/abs/2410.13571)]            |   [[‚úì](https://drivedreamer4d.github.io/)]    |  [[‚úì](https://github.com/DriveDreamer4D/DriveDreamer4D)]  |   ‚úì   |   ‚úì   |  ‚úó   | 2.0 |
|   **Drive&Gen** | IROS 2025  | Drive&Gen: Jointly Learning to Drive and Generate for Autonomous Vehicles                    |            [[‚úì](https://arxiv.org/abs/2510.06209)]            |                       ‚úó                       |                              ‚úó                               |   ‚úì   |   ‚úì   |  ‚úì   | 2.0 |
|    **SimWorld** | arXiv2503  | SimWorld: An Open-ended Realistic Simulator for Autonomous Agents                            |                               ‚úó                               |                       ‚úó                       |                              ‚úó                               |   ‚úì   |   ‚úó   |  ‚úì   | 2.0 |
|     **UMGen** | CVPR 2025  | UMGen: Unified Multi-modal Generation for Autonomous Driving                                 |         [[‚úì](https://www.alphaxiv.org/abs/2503.14945)]        |      [[‚úì](https://umgen-ad.github.io/)]       |            [[‚úì](https://github.com/UMGen-AD/UMGen)]          |   ‚úì   |   ‚úó   |  ‚úó   | 2.0 |
| **DriveSim (LLM)** | arXiv2405  | DriveSim: A Community-driven Simulator for Autonomous Driving (LLM World Model Evaluation)   |      [[‚úì](https://arxiv.org/abs/2405.00000)]<br>*(Ref)* |                       ‚úó                       |         [[‚úì](https://github.com/sreeramsa/DriveSim)]         |   ‚úì   |   ‚úì   |  ‚úó   | 2.0 |
|   **InfiniCube** | ICCV 2025  | InfiniCube: Unlimited 3D Scene Generation with World Models                                  |      [[‚úì](https://arxiv.org/abs/2500.00000)]<br>*(ICCV)* |      [[‚úì](https://infinicube.github.io)]      |       [[‚úì](https://github.com/infinicube/InfiniCube)]        |   ‚úì   |   ‚úó   |  ‚úó   | 2.0 |
|      **GEM** | CVPR 2025  | GEM: A Generalizable Ego-Vision Multimodal World Model                                       |            [[‚úì](https://arxiv.org/abs/2412.00000)]            |    [[‚úì](https://gem-world-model.github.io/)]  |         [[‚úì](https://github.com/gem-world-model/GEM)]        |   ‚úì   |   ‚úì   |  ‚úó   | 2.0 |
|      **MUVO** | IEEE 2025  | MUVO: A Multimodal Generative World Model for Autonomous Driving with Geometric Consistency  |            [[‚úì](https://arxiv.org/abs/2311.11762)]            |    [[‚úì](https://muvo-world-model.github.io/)] |        [[‚úì](https://github.com/muvo-world-model/MUVO)]       |   ‚úì   |   ‚úó   |  ‚úì   | 2.0 |
|    **UniFuture** | arXiv2503  | UniFuture: Seeing the Future through Unified Multi-Modal Generation                          |            [[‚úì](https://arxiv.org/abs/2503.00000)]            |                       ‚úó                       |                              ‚úó                               |   ‚úì   |   ‚úó   |  ‚úó   | 2.0 |
|   **Cosmos-7B** | arXiv2506  | Cosmos-7B: A Multi-Modal World Model for Autonomous Driving (NVIDIA)                         |            [[‚úì](https://arxiv.org/abs/2501.03575)]            |   [[‚úì](https://research.nvidia.com/labs/cosmos)] |            [[‚úì](https://github.com/NVIDIA/Cosmos)]           |   ‚úì   |   ‚úó   |  ‚úì   | 2.0 |
|    **MaskGWM** | CVPR 2025  | MaskGWM: Masked Generative World Model for Autonomous Driving                                |            [[‚úì](https://arxiv.org/abs/2500.00000)]            |                       ‚úó                       |                              ‚úó                               |   ‚úì   |   ‚úó   |  ‚úó   | 2.0 |
| **DriveDreamer-2** | AAAI 2025  | DriveDreamer-2: LLM-Enhanced World Models for Autonomous Driving                             |            [[‚úì](https://arxiv.org/abs/2403.06845)]            |    [[‚úì](https://drivedreamer-2.github.io/)]   |      [[‚úì](https://github.com/DriveDreamer/DriveDreamer-2)]   |   ‚úì   |   ‚úó   |  ‚úì   | 2.0 |
|      **MiLA** | arXiv2503  | MiLA: Multi-View Long-Horizon Autonomous Driving Video Generation                            |            [[‚úì](https://arxiv.org/abs/2503.15875)]            |                       ‚úó                       |                              ‚úó                               |   ‚úì   |   ‚úó   |  ‚úó   | 2.0 |
|     **GAIA-2** | arXiv2503  | GAIA-2: A Generalist Generative World Model for Autonomous Driving (Wayve)                   |             [[‚úì](https://wayve.ai/thinking/gaia-2/)]          |     [[‚úì](https://wayve.ai/thinking/gaia-2/)]  |                              ‚úó                               |   ‚úì   |   ‚úó   |  ‚úó   | 2.0 |
|      **DiVE** | ICLR 2025  | DiVE: Diverse Video Generation for Autonomous Driving                                        |            [[‚úì](https://arxiv.org/abs/2504.19614)]            |                       ‚úó                       |                              ‚úó                               |   ‚úì   |   ‚úó   |  ‚úì   | 2.0 |
|    **BEVWorld** | ICLR 2025  | BEVWorld: A Multimodal World Model for Autonomous Driving                                    |       [[‚úì](https://arxiv.org/abs/2405.00000)]<br>*(Rel)* |                       ‚úó                       |                              ‚úó                               |   ‚úì   |   ‚úì   |  ‚úì   | 2.0 |
|    **UniScene** | CVPR 2025  | UniScene: Unified Scene Generation with 4D Occupancy and Video                               |            [[‚úì](https://arxiv.org/abs/2405.00000)]            |                       ‚úó                       |                              ‚úó                               |   ‚úì   |   ‚úó   |  ‚úì   | 2.0 |
|     **HERMES** | ICCV 2025  | HERMES: Holistic Emergent Reasoning in Multimodal Environments for Simulation                |                               ‚úó                               |    [[‚úì](https://github.com/LMD0311/Awesome-World-Model)]   |                              ‚úó                               |   ‚úì   |   ‚úì   |  ‚úó   | 2.0 |
|  **GaussianWorld** | CVPR 2025  | GaussianWorld: 4D Gaussian Splatting for Occupancy Prediction                                |            [[‚úì](https://arxiv.org/abs/2312.00000)]            |                       ‚úó                       |    [[‚úì](https://github.com/GaussianWorld/GaussianWorld)]     |   ‚úì   |   ‚úó   |  ‚úó   | 2.0 |
|    **OccProphet** | ICLR 2025  | OccProphet: Efficient 4D Occupancy Forecasting with Generative Models                        |            [[‚úì](https://openreview.net/forum?id=OccProphet)]  |                       ‚úó                       |                              ‚úó                               |   ‚úì   |   ‚úó   |  ‚úó   | 2.0 |
| **Drive-OccWorld** | AAAI 2025  | Drive-OccWorld: Vision-Centric 4D Occupancy World Model                                      |            [[‚úì](https://arxiv.org/abs/2405.00000)]            |                       ‚úó                       |         [[‚úì](https://github.com/wzzheng/Drive-OccWorld)]     |   ‚úì   |   ‚úì   |  ‚úó   | 2.0 |
|    **LidarDM** | ICRA 2025  | LidarDM: Generative LiDAR Simulation in a Latent Space                                       |              [[‚úì](https://arxiv.org/abs/2404.02903)]              |   [[‚úì](https://vzyrianov.github.io/lidardm)]  |           [[‚úì](https://github.com/vzyrianov/lidardm)]          |   ‚úì   |   ‚úó   |  ‚úì   | 2.0 |
|  **DynamicCity** | ICLR 2025  | DynamicCity: Large-Scale Lidar Generation from Open-Source Data                              |              [[‚úì](https://arxiv.org/abs/2405.00000)]              |     [[‚úì](https://dynamic-city.github.io/)]    |         [[‚úì](https://github.com/Tsinghua-MARS-Lab/DynamicCity)]        |   ‚úì   |   ‚úó   |  ‚úó   | 2.0 |
|  **LiDARCrafter** | arXiv2508  | LiDARCrafter: Controllable LiDAR Generation for Autonomous Driving                           |              [[‚úì](https://arxiv.org/abs/2500.00000)]              |                       ‚úó                       |                               ‚úó                                |   ‚úì   |   ‚úì   |  ‚úó   | 2.0 |
|    **DriVerse** | ACM MM 25  | DriVerse: Diverse Driving Scene Generation with World Models                                 |              [[‚úì](https://arxiv.org/abs/2407.00000)]              |                       ‚úó                       |                               ‚úó                                |   ‚úì   |   ‚úó   |  ‚úó   | 2.0 |
| **SceneDiffuser++**| CVPR 2025  | SceneDiffuser++: Controllable Generation for Interactive Traffic Simulation                  |              [[‚úì](https://arxiv.org/abs/2306.15682)]              |    [[‚úì](https://scenediffuser.github.io/)]    |         [[‚úì](https://github.com/Localroute/SceneDiffuser)]     |   ‚úì   |   ‚úì   |  ‚úó   | 2.0 |
|      **WoTE** | ICCV 2025  | WoTE: World of Trajectory Embeddings for Autonomous Driving                                  |              [[‚úì](https://arxiv.org/abs/2400.00000)]              |                       ‚úó                       |                               ‚úó                                |   ‚úì   |   ‚úì   |  ‚úó   | 2.0 |
|    **PreWorld** | ICLR 2025  | PreWorld: Pre-training World Models for 3D Occupancy Forecasting                             |              [[‚úì](https://arxiv.org/abs/2405.00000)]              |                       ‚úó                       |                               ‚úó                                |   ‚úì   |   ‚úì   |  ‚úó   | 2.0 |
|    **Occ-LLM** | ICRA 2025  | Occ-LLM: Occupancy-Language Model for Autonomous Driving                                     |              [[‚úì](https://arxiv.org/abs/2400.00000)]              |                       ‚úó                       |                               ‚úó                                |   ‚úì   |   ‚úì   |  ‚úó   | 2.0 |
|   **RenderWorld** | ICRA 2025  | RenderWorld: World Model for 4D Scene Generation and Rendering                               |              [[‚úì](https://arxiv.org/abs/2405.00000)]              |                       ‚úó                       |                               ‚úó                                |   ‚úì   |   ‚úì   |  ‚úó   | 2.0 |
|  **AD-L-JEPA** | arXiv2501  | AD-L-JEPA: Joint Embedding Predictive Architecture for Autonomous Driving (LeCun-Style)      |       [[‚úì](https://arxiv.org/abs/2400.00000)]<br>*(Concept)* |                       ‚úó                       |                               ‚úó                                |   ‚úì   |   ‚úó   |  ‚úì   | 2.0 |
|   **MoVieDrive** | arXiv2508  | MoVieDrive: Motion-Controllable Video Generation for Autonomous Driving                      |              [[‚úì](https://arxiv.org/abs/2500.00000)]              |                       ‚úó                       |                               ‚úó                                |   ‚úì   |   ‚úì   |  ‚úó   | 2.0 |
|      **DIO** | CVPR 2025  | DIO: Diffusion-based Implicit Occupancy for Autonomous Driving                               |              [[‚úì](https://arxiv.org/abs/2404.00000)]              |                       ‚úó                       |                               ‚úó                                |   ‚úì   |   ‚úó   |  ‚úì   | 2.0 |
|     **Raw2Drive** | arXiv2505  | Raw2Drive: End-to-End Autonomous Driving from Raw Sensor Data                                |              [[‚úì](https://arxiv.org/abs/2400.00000)]              |                       ‚úó                       |                               ‚úó                                |   ‚úì   |   ‚úì   |  ‚úó   | 2.0 |


# üìÑ 2. Progressive Robustness Analysis: 1.0, 2.0 and 3.0

comming soon...

## 2.1
